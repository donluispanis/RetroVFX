\chapter{Demo final}

\section{Introducción}

Hasta ahora hemos estado revisando algunos de los efectos gráficos más conocidos y comunes en el mundo de la \emph{demoscene}, analizándolos desde el punto de vista más analítico posible pero también intentando comprender su esencia y trasfondo.\\

Los efectos gráficos son el pilar, la base, que construye el mundo de la \emph{demoscene}, pero un solo efecto no hace una demo, pues una demo consiste en un conjunto de efectos gráficos compilados en un solo ejecutable, normalmente acompañados además de música que se reproduce de forma sincronizada.\\

Tras haber estudiado todos los efectos expuestos anteriormente, llega el momento de utilizar el conocimiento adquirido para intentar generar un obra, una \textbf{demo}, lo más interesante posible. Para ello, será necesario no sólo aplicar lo aprendido, si no también saber hacerlo de una forma que tenga una cierta coherencia en conjunto, de modo que resulte visualmente agradable. No hemos de olvidar que, al fin y al cabo, la \emph{demoscene} es tanto una práctica de ingeniería como de arte.\\

Si bien en este trabajo para nada se aspira a lograr una obra de arte, sí que se perseguirá un cierto sentido estético a lo largo de la composición, de forma que la compilación de todas las demos anteriores resulte lo más coherente y orgánica posible.\\

Como referencias a esta demo se pueden tomar todas aquellas que se han citado y mostrado previamente, pues esta demo pretende ser un humilde tributo y una humilde revisión de la cultura de la \emph{demoscene}, yendo a sus orígenes y efectos más clásicos y trayéndolos de vuelta a los computadores de hoy en día, ejecutando únicamente por CPU y en tiempo real.\\

\section{Planteamiento inicial}

Para desarrollar esta demo hay varias limitaciones o retos de base que nos debemos plantear. En primer lugar, la música juega un factor clave en las demos, y sin embargo hasta ahora no tenemos ningún mecanismo para generar sonido.\\

Además, la demo se ejecutará exclusivamente en la CPU del ordenador, lo cual si bien resulta muy interesante, dado que pone en valor las capacidades de cómputo de un ordenador, también resulta un factor limitante, pues la manipulación de millones de píxeles por segundo no es una tarea trivial, y aún menos si hay operaciones matemáticas complejas de por medio. Es por ello que deberemos aplicar todo lo aprendido para tratar de optimizar y aprovechar el rendimiento al máximo, y cuando esto no sea posible, buscar otras opciones o caminos que enmascaren las limitaciones técnicas de la máquina.\\

Por otro lado, los efectos gráficos que hemos mostrado hasta ahora son tan sólo muestras simplificadas, de modo que resulten lo más explícitas y entendibles posible, pero ahora es el momento de buscar resultados más complejos o interesantes a partir de la base que ya ha sido planteada.\\

Por último, los efectos gráficos creados hasta el momento son bastante distintos o inconexos entre sí, por lo que será importante encontrar un modo orgánico de generar transiciones entre los mismos o combinarlos de una forma coherente.\\

A grandes rasgos, estas son las tareas necesarias para elaborar nuestra demo final:

\begin{itemize}
	\item Permitir la generación de sonido o música
	\item Aplicar o combinar todos y cada uno de los efectos gráficos explicados anteriormente
	\item Aplicar música a la demo coordinada con los efectos gráficos
\end{itemize}

\section{Generar sonido}

Antes de saltar a la implementación, conviene explicar muy brevemente como se representa el sonido de forma digital. Se asume, no obstante, que se conoce de forma básica el funcionamiento del sonido (física de ondas) y su representación matemática. Como ya sabemos, el sonido no es más que una vibración, una oscilación y por tanto, un movimiento ondulatorio. Si se requiere de un breve repaso sobre el funcionamiento de una onda, se puede encontrar en el planteamiento formal del efecto de deformaciones de imagen [\ref{sec:deformaciones}]\\

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{archivos/soundWave}
	\caption{Onda sinusoidal y su discretización}
	\label{fig:soundWave}
\end{figure}

Como podemos ver en la figura [\ref{fig:soundWave}], un sonido se puede representar como una onda (o una combinación de ondas). En el dominio analógico (en rojo), una onda es continua, sin embargo, en el dominio digital (en azul) solo se puede representar una cantidad discreta de valores de la onda, con la consiguiente pérdida de precisión. Es por ello, que para almacenar una onda en el dominio digital definimos una frecuencia de muestreo (equivalente a las líneas verticales de la imagen) y un formato o resolución de muestra (equivalente a las líneas horizontal en la imagen) de modo que cualquier valor intermedio, que no pueda ser representado, será aproximado al valor más cercano.\\

Habiendo dejado esto claro, pasamos a intentar generar sonido por computador. Siguiendo con la dinámica general de este trabajo, la generación de sonido debería ser, en la medida de lo razonable, gestionada por nosotros. La idea inicial es la de usar una librería de sonido para la música del mismo modo que usamos OpenGL para los gráficos, es decir, usar una librería que actúe simplemente como envoltorio y nos genere una capa de abstracción con respecto al sistema operativo, pero una vez hecho esto, generar el sonido desde cero.\\

Tras una breve investigación, las dos opciones más factibles parecían OpenAL\footnote{\url{https://www.openal.org}} y PortAudio\footnote{\url{http://www.portaudio.com}}. Si bien OpenAL es el equivalente directo de OpenGL pero para audio, PortAudio acabó siendo la librería elegida. OpenAL es una librería más estandarizada y potente, que permite generar sonido en 3D y tiene un modo de funcionamiento similar al de su casi homónimo OpenGL. Pero esta potencia viene al coste de una mayor complejidad de uso. PortAudio, en cambio, siendo una librería también de código abierto y multiplataforma, se centra en la simplicidad. Y por ello mismo se optó por ella, ya que parecía innecesario tener que aprender a manejar toda una librería potente y completa con el mero objetivo de usarla como una abstracción de cara al sistema operativo.\\

Una vez tenemos la librería elegida, llega el momento de empezar a implementar nuestro sistema capaz de generar sonido. Todo lo que PortAudio necesita para empezar a funcionar es inicializar la librería y crear un flujo (\emph{stream}) de sonido, al que se le pasa una función delegada controlada por el usuario.\\

\begin{lstlisting}[style=C-color, caption={Código necesario para inicializar PortAudio},label=cod:initialisePortAudio]
Pa_Initialize();
Pa_OpenDefaultStream(&stream, INPUT_CHANNELS, OUTPUT_CHANNELS, paFloat32, SAMPLE_RATE, FRAMES_PER_BUFFER, AudioCallback, 0);
Pa_StartStream(stream);
\end{lstlisting}

Para entender no obstante, cómo funciona PortAudio y los parámetros que nos pide, debemos entender cómo funciona el audio por computador. Como podemos ver en el código [\ref{cod:initialisePortAudio}], una vez inicializamos la librería, abrimos un flujo de sonido. Para hacer esto, no obstante, debemos pasar una serie de parámetros significativos. El primero de ellos, \emph{stream}, se trata simplemente de una estructura del tipo \emph{PaStream}. Esto es un tipo definido por los creadores de la librería y del que realmente no tendremos que preocuparnos, pues es gestionado internamente y no tendremos que realizar ningún tipo de operación con el mismo. La función principal de este tipo es la gestión de distintos canales de entrada y salida de sonido. A continuación debemos indicar los canales de entrada y de salida. Un canal de entrada se corresponde con una fuente de entrada de sonido. Aunque un canal no se corresponde necesariamente a un dispositivo, normalmente un canal de entrada se corresponde con un único dispositivo de grabación. Si en nuestra demo necesitásemos grabar audio, necesitaríamos entonces al menos un canal de entrada. Un canal de salida se corresponde normalmente, aunque no de forma necesaria, con un solo dispositivo de reproducción de audio, o en otras palabras, con un altavoz. Como en nuestra demo no necesitaremos grabar audio pero sí queremos reproducir audio estéreo, necesitaremos pues definir dos canales de salida.\\

Como nota, puntualizar que como se ha dicho anteriormente, un canal de entrada o salida no se corresponde necesariamente con un dispositivo físico. Esto es porque podemos, por ejemplo, definir dos canales de entrada que se correspondan con un único dispositivo de grabación, y sin embargo, dar a cada entrada de audio un tratamiento distinto. Por ejemplo, usar la entrada de un canal para generar eco y la del otro para generar distorsión, para posteriormente combinar los dos canales de entrada en un único canal de salida que tenga ambos efectos combinados. Del mismo modo, también es posible redirigir más de un canal al mismo dispositivo de reproducción. Por tanto, no existe una correspondencia directa entra canal y dispositivo, si bien es cierto que en muchos casos la suele haber.\\

Volviendo al código en [\ref{cod:initialisePortAudio}], una vez hemos definido que queremos dos canales de salida, llega el momento de definir el formato de muestra. Esto es, definir qué formato tendrá una única muestra de sonido. El valor de una muestra representa el valor de la amplitud del sonido en un instante dado. El sonido de los primeros ordenadores, el tan conocido como \emph{música de 8 bits}, tenía un formato de 8 bits interpretados como un entero por muestra. Esto quiere decir que la unidad mínima de sonido reproducible ocupaba 8 bits, y por tanto podía tener 256 valores distintos para la amplitud, que, para tratarse de sonido, podemos apreciar que es una resolución muy baja. De ahí que la música de 8 bits sonase robótica y poco orgánica, entre otras causas. De hecho, la música en 8 bits tan solo permitía 128 valores distintos, si tenemos en cuenta que en una onda que oscila en el origen, la mitad de los valores están por encima del cero y la otra mitad por debajo; por lo que de forma efectiva, contamos con 128 valores y su equivalente negativo. La música en 16 bits, que fue el siguiente paso, ya permitía definir más de 64000 valores distintos para la amplitud. Si escuchamos de hecho la diferencia entre la música de 16 bits y la música de 8 bits, se denota un cambio significativo. El formato que nosotros definimos en nuestra demo, no obstante, es el de un número en coma flotante de 32 bits. Nuestra amplitud máxima será 1 y nuestra amplitud mínima del sonido generado será -1. No obstante, como trataremos con números decimales, dispondremos de una gran resolución.\\

A continuación, una vez definido el formato de muestra (cuántos bits por muestra y cómo se deben interpretar -entero, coma fija, coma flotante...-) definimos el ratio de muestra, comúnmente denominado como la \emph{frecuencia de muestreo}, o en otras palabras, cuántas muestras queremos por segundo. Tal y como indica el teorema del muestro de Nyquist\footnote{\url{https://es.wikipedia.org/wiki/Teorema_de_muestreo_de_Nyquist-Shannon}}, para generar un sonido a una frecuencia determinada, necesitamos al menos el doble de muestras por segundo que la frecuencia que se pretende muestrear. De media, el ser humano es capaz de percibir frecuencias de entre 20 y 20000 Hercios, de modo que si queremos tener la habilidad de generar cualquier frecuencia audible, necesitaremos al menos 400000 muestras por segundo. En nuestra demo definimos una frecuencia de muestreo de 44100 muestras por segundo. El motivo de la elección de este número se debe a motivos históricos, ya que era la frecuencia de muestreo de los CD, ligeramente superior al espectro de sonido audible por cuestiones de formato y conveniencia\footnote{\url{https://es.wikipedia.org/wiki/Frecuencia_de_muestreo}}.\\

A continuación debemos definir la cantidad de muestras por \emph{buffer}. Como acabamos de explicar, para reproducir un sonido en cualquier frecuencia audible, es necesario contar con al menos 40000 muestras por segundo, y en nuestro caso definimos 44100 muestras de sonido por segundo. Pasar estas muestras una a una sería extremadamente poco eficiente, por no decir imposible. La tarjeta de sonido es la encargada de generar y reproducir audio, de modo que cada vez que reproducimos audio, la CPU debe comunicarse con la tarjeta de sonido. 40000 accesos por segundo a la tarjeta de sonido para enviar un solo dato resulta descabellado, y muy lento. Es por ello que se define un \emph{buffer}. Cuando la CPU le pasa datos a la tarjeta de sonido, no lo hace de uno en uno, si no que manda la información en bloques de datos, reduciendo así la cantidad de comunicaciones con la tarjeta de sonido, que son operaciones bloqueantes. Con este parámetro, podemos definir el tamaño de los bloques de datos que se le pasan a la tarjeta de sonido. Bloques muy pequeños implican muchos accesos a la tarjeta de sonido, bloques muy grandes implican una gran cantidad de datos que transferir y una tasa de actualización muy baja (dado que nuestra función delegada se encarga de generar un bloque de datos por llamada, contando con la información en el momento de llamada, por lo que si esta información se actualiza a mitad de la generación de un bloque, la actualización no se verá reflejada hasta la siguiente llamada a nuestra función). Por tanto, conviene elegir un tamaño de \emph{buffer} que resulte razonable, ni demasiado pequeño, ni excesivo. En nuestra demo definimos un tamaño de 256 muestras por \emph{buffer}, lo que se traduce en unos 170 accesos a la tarjeta de sonido por segundo, y unas 170 llamadas a nuestra función delegada por segundo. Del mismo modo, el tamaño de cada \emph{buffer} será de 2KB (4 bytes -32 bits- por muestra, dos canales, 256 muestras por  canal por \emph{buffer}), un tamaño que no resulta trivial pero que es muy pequeño.\\

Tras ello, los siguientes dos parámetros que hemos de pasar son una función delegada a la que PortAudio llamará de forma interna para generar sonido y, de forma opcional, una estructura definida por el usuario. En nuestro caso, realizaremos todas las operaciones necesarias desde la función delegada, y tenemos todos los datos que necesitamos en nuestra clase. Podremos acceder a estos datos desde nuestra función delegada, ya que es un miembro estático de nuestra clase para reproducir audio. Por tanto, pasaremos un 0 (también sería posible y equivalente en este caso pasar un \emph{nullptr}) para indicar que no haremos uso de ninguna estructura de datos definida por el usuario.\\

Llega ahora el momento de echar un vistazo a la función delegada que puede ser definida por el usuario:\\

\begin{lstlisting}[style=C-color, caption={Función delegada que pasamos a PortAudio},label=cod:audioCallback, escapechar=|]
int Imp_Audio::AudioCallback(const void *inputBuffer, void *outputBuffer,
                             unsigned long framesPerBuffer,
                             const PaStreamCallbackTimeInfo *timeInfo,
                             PaStreamCallbackFlags statusFlags,
                             void *userData)
{
    float *out = (float *)outputBuffer;
    static long int currentCount = 0;

    for (unsigned long i = 0; i < framesPerBuffer; i++)
    {
        currentCount++;

        Imp_Audio::UpdateNotes(currentCount);

        *out++ = Imp_Audio::GetLeftValue();  /* left */ | \label{line:left}|
        *out++ = Imp_Audio::GetRightValue(); /* rigth */| \label{line:right}|
    }
    return 0;
}
\end{lstlisting}

Aunque la cantidad de parámetros que recibe la función delegada puede abrumar a primera vista, la realidad es que apenas usamos unos pocos, como podemos ver en el código [\ref{cod:audioCallback}].\\

No usamos el \emph{inputBuffer}, dado que no hemos definido ningún canal de entrada, del mismo modo que tampoco usamos las variables \emph{timeInfo}, \emph{statusFlags} o \emph{userData}, las dos primeras porque son variables que nos aportan información extra pero que no nos resultan especialmente relevantes y la última porque es el argumento que se corresponde con la estructura de datos definida por el usuario que en nuestro caso hemos decidido no definir. Por tanto, sólo estamos interesados en dos variables, el \emph{outputBuffer}, que se corresponde con el \emph{buffer} para la salida de datos, es decir, es el \emph{buffer} cuyos datos son pasados a la tarjeta de sonido para ser reproducidos por el ordenador y por otro lado, la variable \emph{framesPerBuffer}, que recordemos que habíamos definido previamente con el valor 256 y que nos indica por cada llamada a la función, cuántas muestras por canal debemos incluir en el \emph{buffer}. Si nos fijamos en las líneas [\ref{line:left}] y [\ref{line:right}], veremos que en estas líneas asignamos un valor a la posición actual del \emph{buffer} y a continuación la incrementamos. Como podemos recordar, hemos definido dos canales de salida de audio, dado que queremos audio estéreo. Esto implica, por tanto, que nuestro \emph{buffer} deberá ser rellenado con muestras para ambos canales. Estas muestras se leen de forma intercalada, de modo que si visualizamos nuestro \emph{buffer} como un \emph{array}, su primer valor se corresponderá con la primera muestra del canal izquierdo, su segundo valor con la primera muestra del canal derecho, su tercer valor con la segunda muestra del canal izquierdo, y así sucesivamente... Esto nos permite, de forma bastante sencilla, asignar valores a nuestros canales de salida de audio.\\

Antes de continuar ahondando en el funcionamiento del sistema de sonido, vale la pena explicar su funcionamiento de forma genérica, a partir de lo previamente construido.\\

En nuestro sistema, tenemos un vector estático de notas. Podemos ver la estructura de una nota en la figura [\ref{fig:note}]. Por cada muestra que añadimos al \emph{buffer} de salida, actualizamos los valores de todas las notas que se están reproduciendo actualmente, basándonos en la variable entera \emph{currentCount}, que se actualiza por iteración. De esta modo, usamos \emph{currentCount} para actualizar el valor de nuestras notas de forma muy similar a como usamos el valor de \emph{deltaTime} para actualizar nuestras demos. De hecho, ambas variables tienen una relación directa con el tiempo, ya que \emph{deltaTime} representa el tiempo transcurrido desde el fotograma anterior mientras que \emph{currentCount} representa el número de muestra que se está actualizando, y como sabemos, actualizamos 44100 muestras por segundo, por lo que cada 44100 actualizaciones de este valor, habrá transcurrido un segundo.\\

Una vez actualizamos el valor de nuestras notas, llega el momento de asignarlas a la salida. Para ello, llamamos a dos funciones que respectivamente nos devolverán el valor para la salida de audio izquierda y el valor para la salida de audio derecha, basándose en la posición de las notas que se están reproduciendo actualmente.\\ 

%@startuml
%
%class Note << (S,#FF7700) Struct >>
%{
%  +float (*generateWave)(frequency, count)
%  +Envelope envelope
%  +float frequency
%  +float volume
%  +float position
%  +float lifetime
%  +float currentEnvelopeValue
%  +float resultingSound
%}
%
%class Envelope << (S,#FF7700) Struct >>
%{
%  +float attack
%  +float decay
%  +float sustain
%  +float release
%  +float peakAmplitude
%  +float sustainAmplitude
%  
%}
%
%hide empty members
%
%@enduml

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{archivos/note}
	\caption{Estructura de una nota y su envolvente}
	\label{fig:note}
\end{figure}

Una vez que entendemos de forma simplificada como funciona nuestro sistema, llega el momento de definir qué es una nota y cómo se utiliza. Podemos ver su estructura en la figura [\ref{fig:note}].\\

Una nota musical se define principalmente por los siguientes parámetros: su forma de onda, su frecuencia, su volumen y su envolvente. La forma de onda en nuestro caso es generada por una función delegada, que a partir de la frecuencia deseada y el número de muestra, genera el valor correspondiente. De este modo, podemos asignar distintas formas de onda a distintas notas con gran facilidad, simplemente cambiando la función delegada de la misma. La frecuencia se corresponde con la frecuencia de la onda y el volumen con la amplitud, valor que oscilará entre 0 y 1. Por último, ya solo queda definir la envolvente, lo cual es algo más complejo.\\

La envolvente de una nota, o de un sonido en general, es algo así como "el ciclo de vida" de un sonido. Podemos ver la forma o estructura habitual de una envolvente en la figura [\ref{fig:ADSR}]. A este tipo de envolvente se la denomina comúnmente envolvente \emph{ADSR}, siendo estas siglas la denominación de las fases de la envolvente, en español, ataque, decaimiento, sostenimiento y relajación.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{archivos/ADSR}
	\caption{Envolvente de un sonido - Fuente: \href{https://en.wikipedia.org/wiki/Envelope_(music)\#/media/File:ADSR_parameter.svg}{Wikipedia}, por \href{https://commons.wikimedia.org/wiki/User:Abdull}{Abdull}}
	\label{fig:ADSR}
\end{figure}

Vamos a clarificar qué es una envolvente con un ejemplo práctico: tocar una nota en un piano real. Cuando tocamos una nota en un piano, hay un momento en el que se pasa del silencio a emitir un sonido. Esta es la fase de ataque, que se produce en el instante en que el martillo golpea las cuerdas. Tras esto, la amplitud (volumen) de la nota decae levemente, siendo esta la fase de decaimiento, pero, si mantenemos la nota pulsada, sigue sonando a una amplitud inferior, siendo esta la fase de sostenimiento. Ya por último, una vez dejamos de presionar la tecla, o si transcurre el tiempo suficiente, el sonido empieza a decaer hasta que se desvanece, entrando por tanto en la fase de relajación. Prácticamente todos los instrumentos tienen estas fases, en mayor o menor medida. La envolvente de un sonido, por tanto, define la evolución del volumen del sonido a lo largo del tiempo, y define de forma drástica la forma en la que suena un instrumento. Por ejemplo, si pulsamos una tecla en un piano lentamente no sonará igual que si la pulsamos de golpe, porque tendrá una fase de ataque distinta, siendo la segunda mucho más breve. Además de definir estas cuatro fases, definimos dos variables más, la amplitud máxima y la amplitud de sostenimiento. La primera define el volumen que la nota alcanza tras la fase de ataque. La segunda define el volumen de la nota una vez que este decae y se sostiene, en la fase de sostenimiento.\\

Por tanto, pues, cada vez que actualicemos el valor de nuestra nota, también deberemos actualizar el valor de la envolvente en el ciclo de vida actual de la nota. Para ello, simplemente debemos crear una función que sea capaz de interpolar entre estos estados. Es decir, dado un tiempo de ataque, debe interpolar entre el reposo (0) y la amplitud máxima, una vez que se alcanza esta amplitud y acaba la fase de ataque, el volumen de la nota decae en la fase de decaimiento tanto tiempo como se especifique hasta estabilizarse en la amplitud de sostenimiento, que se mantendrá constante durante toda esta fase. Tras ello, entraremos en la última fase y en el final del ciclo de la vida de la nota, donde pasamos de la amplitud de sostenimiento al reposo de nuevo, el silencio. Es en este momento cuando termina el ciclo de vida de la nota.\\

Por tanto, en la estructura de la nota, que podemos ver en la figura [\ref{fig:note}], las primeras cuatro variables contienen información sobre la nota que se está reproduciendo, mientras que las tres últimas contienen su estado: el tiempo de vida de la nota (cuando el tiempo de vida de la nota es igual a la duración de la envolvente, se considera que la nota ha terminado y por tanto se elimina de nuestro vector de notas), el valor de la envolvente para el tiempo de vida actual, (que dependerá de la fase de la envolvente en que nos encontremos y modificará el volumen de la nota) y el sonido resultante, (que se corresponde con el valor de retorno del método delegado que la nota contiene).\\

La única variable de la que aún no hemos hablado es en realidad una bastante interesante, la variable \emph{position}. El valor de esta variable oscila entre 0 y 1, 0 representando el canal izquierdo y e1 1 representando el canal derecho. El valor por defecto de esta variable es \(0.5\), que se corresponde al centro, o en otras palabras, nuestra nota sonando con la misma intensidad por el altavoz izquierdo y el derecho. Si asignamos a esta variable el valor 0, el sonido de nuestra nota se reproducirá solo por el canal izquierdo pero no por el derecho, y lo mismo se aplica a la inversa si aplicamos un valor de 1. Cualquier valor intermedio emitirá sonidos por ambos canales, tendiendo aquellos canales por debajo de \(0.5\) a la izquierda y aquellos por encima de \(0.5\) a la derecha.\\

Ahora que ya hemos explicado cómo funcionan las notas en nuestro sistema, podemos ver por fin el código para actualizarlas y reproducirlas por el canal izquierdo o derecho, como hacemos en el código [\ref{cod:audioCallback}].\\

\begin{lstlisting}[style=C-color, caption={Actualización y obtención del valor de las notas},label=cod:updateNotes, escapechar=|]
void Imp_Audio::UpdateNotes(long int currentCount)
{
    for (auto &note : notes)
    {
        note.resultingSound = note.generateWave(note.frequency, currentCount) * note.currentEnvelopeValue * note.volume;
    }
}

float Imp_Audio::GetLeftValue()
{
    float sum = 0.f;

    for (auto &note : notes)
    {
        float leftAmplitude = 1.f;
        if (note.position > 0.5f)
        {
            leftAmplitude -= (note.position - 0.5f) * 2.f;
        }

        sum += note.resultingSound * leftAmplitude;
    }

    return sum;
}
\end{lstlisting}

En el código [\ref{cod:updateNotes}] se aporta el método para actualizar notas y el método para obtener el valor de muestra para el canal izquierdo. Se omite el del canal derecho ya que es prácticamente equivalente en funcionalidad al del izquierdo.\\

Para actualizar el valor de una nota, lo que hacemos es multiplicar el resultado que nos devuelve nuestro método delegado (en función de la frecuencia y el tiempo actual) por el valor actual de la envolvente de la nota y el volumen general de la nota. Las envolventes no se actualizan en este bucle, si no que son actualizadas en la función \emph{Update} de la propia clase, en lugar de actualizarse dentro de la función delegada que es gestionada por PortAudio. Esta decisión se ha tomado de modo que sea más fácil gestionar la actualización de la envolvente, que depende directamente del tiempo, por lo que es más fácil de actualizar con un intervalo de tiempo (\emph{deltaTime}) que no con un número de muestra (\emph{currentCount}) y también para aliviar la cantidad de cálculos, pues en lugar de tener que actualizar la envolvente por muestra (44100 veces por segundo) la actualizamos por fotograma (unas 60 veces por segundo). Esta decisión tiene sus ventajas e inconvenientes, pues por un lado implica no tener que estar constantemente actualizando la envolvente pero por otro, también facilita que se puedan producir pequeños cortes o cambios bruscos en la intensidad del sonido. En general, y bajo opinión personal, pienso que actualizando la envolvente una vez por fotograma el resultado es suficientemente satisfactorio, pero si se quisiera actualizar por muestra, sería tan sencillo como invocar a la función de actualizar envolvente en el bucle del código [\ref{cod:audioCallback}], pasándole por valor \(1 \div 44100\), es decir, la cantidad de tiempo que transcurre de una muestra hasta la siguiente.\\

A continuación, la función \emph{GetLeftValue} calcula el valor para el canal izquierdo por nota y lo suma. Si el valor de la variable \emph{position} de la nota se halla entre 0 y \(0.5\), entonces el factor  de amplitud en el canal izquierdo para esa nota será de 1, pero el factor para esa nota en el canal derecho será menor que 1. Del mismo modo, si la posición de la nota es superior a \(0.5\), entonces el factor de amplitud en el canal izquierdo será menor, o en otras palabras, la nota sonará con menor intensidad por el canal izquierdo. Por tanto, situada en el centro (\(0.5\)), una nota sonará con su amplitud natural tanto por el canal izquierdo como por el derecho, mientras que si no se sitúa en el centro, su amplitud será menor en un canal o en otro. Una versión refinada de esta implementación sería una en que el módulo del sonido total de la nota siempre fuera 1, por lo que en el centro, el factor para el canal izquierdo y derecho sería \(\sqrt{\frac{1}{1 + 1}} = \sqrt{\frac{1}{2}} \approx 0.707\). No obstante, para evitar complejidad añadida y una mayor carga computacional, se ha optado por la solución que se muestra en código, más sencilla y con un resultado práctico similar.\\

Como podemos ver en la función \emph{GetLeftValue} en el código [\ref{cod:updateNotes}], el valor de cada nota se suma acumulativamente y se devuelve como el valor total para el canal. Recordemos que este valor se corresponde al de la amplitud general de la salida de sonido para el canal, por lo que debe estar comprendido entre -1 y 1. De lo contrario, si sobrepasamos este límite, se producirán artefactos de sonido extraños y desagrables, que en el peor de los casos podrían llegar incluso a dañar nuestros altavoces (aunque en nuestro caso no corremos ese riesgo, dado que PortAudio se encargará de filtrar todos aquellos valores que se salgan de rango). No obstante, queda en manos de quien añada sonidos asegurarse de que la suma de los sonidos no sobrepase el umbral máximo. Por ejemplo, si hacemos sonar dos instrumentos a la vez, deberíamos hacer que cada uno sonase a la mitad de su amplitud, de modo que sumados, como máximo, sumasen la amplitud máxima. De este modo, dejamos al usuario la decisión de la masterización del sonido, que si bien implica una responsabilidad (de lo contrario se producirán artefactos de sonido desagradables) también otorga una mayor flexibilidad.\\

Así pues, recapitulando, hemos creado un sistema que nos permite gestionar y reproducir notas de sonido complejas, con una envolvente asociada y en estéreo. No obstante, y antes de continuar a la siguiente sección, aun nos queda algo fundamental por definir, ¡una forma de generar ondas de sonido!\\

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{archivos/waves}
	\caption{Distintas formas de onda - Fuente: \href{https://upload.wikimedia.org/wikipedia/commons/6/6f/Waveforms.png}{Wikipedia}, por \href{https://commons.wikimedia.org/wiki/User:Omegatron}{Omegatron}}
	\label{fig:waves}
\end{figure}

Históricamente, encontramos cuatro tipos distintos de ondas generadas por ordenador, que podemos ver en la figura [\ref{fig:waves}]. La onda cuadrada y la de diente de sierra son ondas que suenan muy robóticas o metálicas, por tanto muy lejanas al sonido natural. Sin embargo, son muy fáciles de calcular, ya que tienen un muy bajo coste computacional, por lo que los primeros ordenadores y videoconsolas que podían generar sonido, tenían capacidad para generar sólo este tipo de ondas. Al fin y al cabo, para generar un sonido se requiere una gran cantidad de muestras por segundo, por lo que en un ordenador de poca potencia, el cálculo para hallar el valor de una muestra debe ser lo más rápido posible, o de lo contrario, ralentizará la ejecución del programa. Es por ello, por tanto, que se generaban ondas cuadradas (que oscilan entre dos únicos valores, \emph{+amplitud} y \emph{-amplitud}) y las ondas de diente de sierra, cuyo valor de la amplitud se incrementa a lo largo de la longitud de la onda para decaer a 0 al final de cada iteración.\\

Las ondas triangulares son ondas que, siendo mucho más sencillas de calcular que una onda sinusoidal, resultan mucho más orgánicas que las dos anteriores, pues consiste en una interpolación continua entre la amplitud máxima y la máxima negativa. Tiene una carga de cómputo algo más elevada que la de las ondas cuadrada y de diente de sierra pero, sin embargo, ofrece un resultado sonoro bastante más orgánico a un coste relativamente bajo.\\

Por último tenemos las ondas sinusoidales. En la naturaleza, o en el mundo real, el sonido se propaga de manera natural con esta forma de onda. Sin embargo, como bien sabemos, el cálculo del seno es una operación matemática para nada trivial, por lo que este tipo de onda tardaría un tiempo en llegar a los ordenadores. Siempre se podría usar tablas precalculadas en lugar de la operación matemática, pero recordemos que el uso de tablas precalculadas también introduce un cierto factor de complejidad y un error añadido, por su limitación en precisión. Nuevamente, la elección de un técnica u otra depende de la consideración personal.\\

\begin{lstlisting}[style=C-color, caption={Cálculo de una onda sinusoidal con una frecuencia determinada},label=cod:sineWave, escapechar=|]
float Sounds::GetSineWaveValue(float frequency, long int currentCount)
{
    int steps = SAMPLE_RATE / frequency;

    float percentage = currentCount % steps / float(steps);

    return sin(2 * Fast::PI * percentage);
}
\end{lstlisting}

En el código [\ref{cod:sineWave}] vemos la implementación de la función para generar ondas sinusoidales. Como podemos ver, cumple la signatura del método delegado de una nota [\ref{fig:note}], de modo que podemos hacer fácilmente que una nota reproduzca sonido con forma de onda sinusoidal.\\

El sonido que generamos depende de la frecuencia, por lo que lo primero que hacemos es calcular, para la frecuencia dada, la cantidad de muestras necesarias para generar un único ciclo o iteración de la onda. Este valor se corresponde con la frecuencia de muestreo dividida por la frecuencia deseada. Por ejemplo, si tenemos una frecuencia de muestreo de 2000 muestras por segundo y queremos emitir un sonido a 200 Hercios, por tanto, 200 oscilaciones por segundo, entonces se deberá producir una oscilación a cada \(\frac{2000}{200} = 10\) muestras.\\

Una vez hemos hallado la cantidad de muestras por oscilación, hallamos el punto o porcentaje en el que nos encontramos dentro de la oscilación. Para hacer esto, hallamos el módulo del número de muestra actual en función de la cantidad de muestras por oscilación y lo dividimos por la cantidad de muestras por oscilación. Por ejemplo, si estamos en la muestra 25 y tenemos 10 muestras por oscilación, entonces hallamos el módulo \(25\mod 10 = 5\) y lo dividimos entre la cantidad de muestras por oscilación \(\frac{5}{10} = 0.5\), hallando que nos encontramos a la mitad de la oscilación.\\

Una oscilación completa equivale a una circunferencia completa, es decir, \(2\pi\), por lo que sabiendo el punto de la oscilación en que nos encontramos, sólo tenemos que multiplicar por \(2\pi\) y calcular el seno del valor obtenido para hallar la amplitud de nuestra onda a una frecuencia determinada en un instante de tiempo dado.\\

Podríamos pensar que ya hemos acabado con la generación de sonido, pero aún nos queda ser capaces de generar un sonido fundamental, ¡el ruido!\\

El ruido en esencia es la aleatoriedad, la desorganización, el caos. Un ruido normalmente tiene valores de amplitud para una gran cantidad de frecuencias en el espectro. Todo aquel sonido que no es armónico (no se repite periódicamente) puede ser potencialmente considerado un ruido.\\

Nos podemos preguntar para qué es necesaria la generación de ruido. La respuesta es que es fundamental. La mayoría de instrumentos de percusión, por ejemplo, no son más que generadores de distintos tipos de ruido. El sonido de un tambor, por ejemplo, no es más que un ruido con una envolvente, de modo que tiene un ataque y decaimiento muy breve y, dependiendo del tambor, una relajación más o menos duradera. Adicionalmente, también podemos usar el ruido para generar sonidos de ambiente (agua, viento...) o para dar un toque más orgánico a un instrumento (ya que todos los instrumentos generan una pequeña cantidad de ruido. Por ejemplo, al tocar un piano, el martillo golpeando las cuerdas genera algo de ruido además de un sonido armónico, y si eliminamos este ruido de fondo del sonido del instrumento al generarlo por computador, el resultado se escuchará mucho más artificial).\\

Generar un ruido blanco (aquel que tiene amplitud en todas las frecuencia del espectro\footnote{\url{https://es.wikipedia.org/wiki/Espectro_de_frecuencias}}), es extremandamente sencillo. Como ya hemos dicho, un ruido es aleatoriedad, por lo que para generar un ruido blanco, tan sólo necesitaremos generar un valor aleatorio comprendido entre -1 y 1 por muestra.\\

Sin embargo, el ruido blanco, si bien sencillo de generar, no se encuentra presente en la naturaleza, y resulta por tanto un sonido poco orgánico, bastante artificial. Es un sonido, por ejemplo, como el que generaban los antiguos televisores cuando perdían la señal.\\

En la naturaleza, el ruido suele tener mayor amplitud en las frecuencias más bajas del espectro y menor amplitud o nula en las frecuencias altas. Es por ello que necesitaremos generar un filtro de pasa baja\footnote{\url{https://en.wikipedia.org/wiki/Low-pass_filter}}. Un filtro de pasa baja nos permite filtrar las frecuencias altas, atenuándolas o eliminándolas, y dejando pasar solo las frecuencias bajas. De forma alternativa, generaremos también un filtro para ruido de pasa alta, que atenúa o elimina las frecuencias bajas. Si bien es posible que acabemos no haciendo uso de este filtro, es interesante disponer del mismo para, potencialmente, poder usarlo en algunos instrumentos.\\

Sin entrar en excesivo detalle, haremos uso de la fórmula para generar estos filtros con retroalimentación, que podemos ver en la figura [\ref{fig:filtros}].\\

\begin{figure}[h]
	\begin{equation}
		y[n] = \alpha x[n] + (1 - \alpha) y[n-1] 
		\label{eq:lowpass}
	\end{equation}
	\begin{equation}
		y[n] = \alpha y[n - 1] + \alpha (x[n] - x[n-1]) 
		\label{eq:highpass}
	\end{equation}
	\caption{Filtros de pasa baja y de pasa alta}
	\label{fig:filtros}
\end{figure}

El valor de la amplitud de un sonido al que se le aplica un filtro de pasa baja [\ref{eq:lowpass}], en un instante dado, equivale al valor de la muestra en ese instante multiplicado por un valor de intensidad definido por el usuario, sumado a la parte restante del valor de intensidad por la salida del filtro en el instante de tiempo anterior.\\

Hallar el resultado de un sonido al que se le aplica un filtro de pasa alta [\ref{eq:highpass}] es ligeramente más complejo, consistiendo en multiplicar el valor de la intensidad por el resultado anterior del filtro sumado a la intensidad multiplicada por el valor del sonido en el instante actual menos el valor del sonido en el instante anterior.\\

En el código [\ref{cod:lowhighpass}] podemos ver la implementación de estos filtros para la generación de ruido. El valor de la intensidad se refiere a la severidad con la que el filtro se aplica, y oscila entre 0 y 1, de modo que con un valor de 1 deja pasar todas las frecuencias y con un valor cercano a 0, deja pasar sólo las frecuencias más graves o más agudas (dependiendo del filtro).\\

\begin{lstlisting}[style=C-color, caption={Aplicación de un filtro de pasa baja y uno de pasa alta a la generación de ruido},label=cod:lowhighpass, escapechar=|]
float Sounds::GetLowPassNoiseValue(float intensity)
{
    static float oldValue = 0;
    float newValue = intensity * GetNoiseValue() + (1 - intensity) * oldValue;
    oldValue = newValue;
    return newValue;
}

float Sounds::GetHighPassNoiseValue(float intensity)
{
    static float oldValueY = 0.f;
    static float oldValueX = 0.f;
    
    float newValueX = GetNoiseValue();
    float newValueY = intensity * oldValueY + intensity * (newValueX - oldValueX);

    oldValueX = newValueX;
    oldValueY = newValueY;

    return newValueY;
}
\end{lstlisting}

Ahora sí, ya disponemos de las herramientas y el marco de trabajo necesarios para poder generar prácticamente cualquier sonido en nuestra demo, de modo que podemos pasar a la creación de la misma.

\section{Crear la demo}

El proceso de creación de la demo, a decir verdad, es más un proceso de prueba y error que un proceso técnico. Al fin y al cabo, la parte técnica ya ha sido implementada en los efectos gráficos anteriores, por lo que ahora lo más relevante es probar y modificar valores para obtener los resultados que deseemos. Como ya se ha comentado anteriormente, buscamos un resultado lo más estético posible.\\

Desde un primer momento hubo una idea que me llamó mucho la atención. Dado que teníamos la capacidad de generar fuego y la capacidad de generar texto, parecía muy interesante tratar de implementar como inicio de la demo un texto de fuego. Tras iterar varias veces sobre la idea y algo de prueba y error, la mejor opción parecía la de crear un texto que apareciera con un \emph{zoom} de entrada y se situase en el centro, con el título de la demo, y prendido en fuego.\\

Para ello, por tanto, era necesario tener un título. Este título debía ser capaz de expresar la esencia y contenido de la demo, y poner en valor sus puntos fuertes. ¿Cuál es el punto fuerte de la demo que quiero hacer? ¿Cuáles son sus limitaciones?\\

Bajo mi punto de vista, su mayor ventaja e inconveniente es uno solo: está generada usando únicamente la CPU del ordenador, sin operaciones con gráficos aceleradas por \emph{hardware}, de modo que esto actúa como un limitante para la potencia o capacidad de la demo pero también como un punto fuerte y de interés, pues demuestra hasta qué punto puede ser potente una CPU en el manejo de operaciones gráficas. Es por ello que se optó por un nombre simpático y directo "CPU-T-U", que leído en inglés suena de forma similar a \emph{CPU to you}, o \emph{CPU para ti} en español. Además, decidí incluir como subtítulo el nombre del creador, pero siguiendo la moda tan común en el mundo de la \emph{demoscene} de usar apodos en lugar de nombres reales, utilicé el apodo que uso en redes sociales, \emph{donluispanis}.\\

La implementación fue bastante sencilla, recordemos que para el efecto de fuego [\ref{sec:fire}], lo que hacíamos era convolucionar una matriz a lo largo de una matriz de valores, de forma que se podría un efecto de disipación que, al relacionarlo con un degradado de color, se asemejaba al fuego. Todo lo que necesitamos hacer ahora es, en nuestra matriz de valores, en lugar de asignar unos pocos valores aleatorios en la parte inferior de la misma, asignar valores de modo que formen letras, y a continuación, convolucionar la tabla para que parezca que las letras están en llamas.\\

Como ya habíamos implementado en nuestro motor gráfico una función para dibujar texto en pantalla, todo lo que necesitábamos hacer era copiar esta funcionalidad y modificarla ligeramente para permitir dibujar texto, en lugar de en una cadena de píxeles que se corresponden a la pantalla, en una cadena de números enteros que se corresponden a una textura. Una vez tenemos esto, tan sólo tenemos que usar el algoritmo para generar el efecto de fuego, que ya vimos en [\ref{cod:finalFire}], modificando levemente valores hasta que el resultado obtenido sea de nuestro agrado.\\

Llegados a este punto, obtenemos el resultado que podemos ver en la figura [\ref{fig:intro}].\\

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{archivos/intro}
	\caption{Inicio de la demo}
	\label{fig:intro}
\end{figure}

No obstante, y aunque estamos tan sólo al inicio, ya nos encontramos con las primeras limitaciones. Queremos que nuestra demo se reproduzca a pantalla completa, no obstante, si usamos la resolución nativa de una pantalla común, en \emph{Full HD}, nos vemos con que tenemos que iterar a través de nada más y nada menos que \(1920 \times 1080 = 2073600\) píxeles por fotograma. Si a esto añadimos que tenemos que mantener también una matriz de valores del mismo tamaño, vemos que de pronto la cantidad de cálculos a realizar por fotograma parece excesiva y muy difícil de mantener con una tasa de refresco aceptable.\\

Es por ello que llega el momento de tomar una primera y dolorosa decisión: aunque reproduzcamos en pantalla completa, nuestra demo tendrá una resolución fija en HD, significando esto que tan sólo tendremos que manipular \(1280 \times 720 = 921600\) píxeles por fotograma. En la práctica, este cambio de resolución no es demasiado evidente, ya que delegamos en el sistema el reescalado de nuestra imagen en HD a la resolución nativa de la pantalla. De este modo, obtenemos un gran mejora de rendimiento (reducimos a más de la mitad la cantidad de cálculos necesarios por fotograma) al precio de perder resolución.\\

Este es un sacrificio necesario, pues si ya calcular el efecto de fuego resulta costoso, cuando intentemos generar efectos más complejos, nos resultará imposible de no reducir la cantidad de píxeles sobre la que iteramos.\\

Además, para el efecto de fuego, hay una optimización más que podemos incluir. Si nos fijamos en la imagen [\ref{fig:intro}], hay mucho espacio vacío en la misma. Por tanto, si en lugar de iterar sobre toda la imagen, sobre todos los píxeles, iteramos sólo sobre el rectángulo que ocupa el título y el rectángulo que ocupa el subtítulo, nos ahorraremos tener que iterar sobre todos aquellos píxeles de espacio "vacío" que sabemos que siempre estarán en negro, reduciendo así aún más la cantidad de píxeles sobre la que operamos y aliviando la carga de cómputo.\\

Una vez hecho esto, y creados nuestro fundido de entrada (el texto se hace cada vez más grande hasta ocupar el centro de la pantalla) y nuestro fundido de salida (un simple fundido a negro, consistente únicamente en multiplicar la intensidad del píxel por un valor de opacidad decreciente), tan sólo nos queda añadir música para la introducción.\\

La introducción tiene un potente aire \emph{retro}, con el texto \emph{pixelado} y un efecto de fuego con una gama de color limitada (definimos un degradado de color de 256 valores). Por tanto, parece adecuado crear un sonido que siga la misma línea de estilo. Para ello, creamos la función delegada que podemos ver en el código [\ref{cod:retroSound}].\\

\begin{lstlisting}[style=C-color, caption={Generación de un sonido retro},label=cod:retroSound, escapechar=|]
float Sounds::CreateRetroSound(float frequency, long int currentCount)
{
    return GetSawtoothWaveValue(frequency * 0.5f, currentCount) * 0.4f +
           GetSquaredWaveValue(frequency, currentCount) * 0.4 +
           GetSquaredWaveValue(frequency * 2.f, currentCount) * 0.15 +
           GetNoiseValue() * 0.05;
}
\end{lstlisting}

Como podemos ver, el sonido que generamos es la combinación de una onda de diente de sierra como base sumada a dos ondas cuadradas, la segunda con el doble de amplitud que la primera, y añadiendo un pequeño ruido de fondo. La suma total de las ondas será siempre un valor comprendido entre -1 y 1. Nos aseguramos de esto multiplicando cada onda por un factor distinto, siendo la suma de todos estos factores 1. Al usar únicamente ondas de diente de sierra y cuadradas, que eran las únicas que los primeros ordenadores con sonido podían generar, obtenemos una sensación de sonido muy \emph{retro}.\\

Usamos esta función delegada en combinación con una envolvente con un ataque lento para generar un sonido de intensidad creciente mientras que el texto aumenta de tamaño en pantalla. El sonido se estabiliza y desvanece conforme el texto desaparece.\\

Con esto, ya tenemos una introducción digna para nuestra demo, tanto a nivel visual como sonoro. Llega el momento de seguir, y entrar ya en el cuerpo de la demo. La forma de proceder me pareció clara, ya que en el proceso de creación de la intro, una idea arraigó fuertemente en mi cabeza.\\

Hemos estado hablando y tratando recientemente con ondas, especialmente a nivel sonoro, aunque también las hemos usado para generar efectos de deformación de imagen [\ref{sec:deformaciones}]. Además, hemos explicado la importancia de la generación de ruido, y cómo se puede usar un ruido filtrado, con un filtro de pasa baja, para generar sonido ambiente, como por ejemplo el del agua. Y es esto lo que me parece especialmente interesante, el agua en movimiento forma ondas, y a su vez, produce ondas sonoras. Usando el efecto de geometría [\ref{sec:geometry}], parecía bastante factible la posibilidad de generar una malla de puntos interconectados y actualizarla periódicamente de modo que ondulase. Con un par de retoques extra y efectos de sonido, se podría obtener un resultado de lo más satisfactorio.\\

Para ello, lo primero que tenemos que hacer es, como ya hemos comentado, crear un objeto 3D [\ref{fig:pointandobject}] que contenga una malla de puntos. Esto es, generar un rejilla de puntos, con dos simples bucles encadenados, e interconectar los puntos entre ellos. Para generar índices, lo que hacemos es unir cada punto con el punto a su derecha y el punto bajo él, como podemos ver en la figura [\ref{fig:grid}]. De este modo, creamos una malla de puntos de forma sencilla.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=6cm]{archivos/grid}
	\caption{Generación de una malla de vértices}
	\label{fig:grid}
\end{figure}

Una vez tenemos nuestra malla de puntos creada y la posicionamos en escena, llega el momento de animarla, de modo que tenga un movimiento ondulatorio. Para ello, implementamos el código que podemos ver en [\ref{cod:applyWaveTransformation}].\\

\begin{lstlisting}[style=C-color, caption={Aplicación de una deformación de onda a nuestra malla de puntos},label=cod:applyWaveTransformation, escapechar=|]
void Imp_Geometry::ApplyWaveTransformation(Object3D &object, float amplitude, float wavelength)
{
    grid.colours.clear();
    for (float j = 0; j < vertexPerDepth; j++)
    {
    
        float wave = sin((j + phase) / wavelength);
    
        for (float i = 0; i < vertexPerWidth; i++)
        {
            grid.points[j * vertexPerWidth + i].Y += amplitude * wave;
            
            grid.colours.push_back((Pixel(0, 0, 125) + Pixel(255, 255, 125) * (1 - (wave + 1) * 0.5f))); |\label{line:colouring}|
        }
    }
}
\end{lstlisting}

Como vemos, todo lo que hacemos es modificar la altura de cada vértice en función de una onda sinusoidal que depende de la posición en la que nos encontramos y la fase, que se incrementa en función del tiempo. Además, también cambiamos el valor del color de cada vértice en función de la onda. Esto es algo que no podíamos hacer previamente, pues en la demo de geometría [\ref{sec:geometry}], definíamos un solo color para todo el objeto. Ahora, nuestro objeto tiene la posibilidad de tener un color por vértice, y añadimos en la función del motor gráfico para dibujar una línea la posibilidad de definir un color inicial y un color final. Si proveemos esta información, entonces la función hace una simple interpolación lineal en la que el color de la línea cambia con su avance.\\

Por tanto, en la línea [\ref{line:colouring}], lo que hacemos es definir un color base de valor (0, 0, 125), que se corresponde con azul oscuro y sumarle un valor (255, 255, 255) que se corresponde con blanco, de modo que cuando la onda se encuentre en su amplitud mínima (-1), el vértice se dibuje de color azul y cuando la onda se encuentre en su amplitud máxima (+1) el vértice se dibuje de color blanco.\\

Esta nueva posibilidad de coloración refuerza la sensación de estar observando un "mar digital". Podemos ver el resultado en la figura [\ref{fig:digitalsea}]. Como observamos, los vértices situados en la "cresta de la ola" son de color blanco, mientras que los situados en su parte más baja, son de color azul oscuro. El color se interpola a lo largo de las líneas y la malla se muestra completamente ondulada.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{archivos/digitalsea}
	\caption{La malla de vértices ondulada y coloreada}
	\label{fig:digitalsea}
\end{figure}

Ahora, llega el momento de añadir un sonido que recuerde al mar. Esto lo hacemos con el código [\ref{cod:seawavesound}]. Realmente, todo lo que estamos haciendo aquí es devolver un ruido filtrado en pasa baja cuya amplitud o volumen es modulada por la frecuencia que pasamos a la función delegada. De este modo, si definimos una frecuencia de 0.5, por ejemplo, entonces se escuchará como una ola "aparece y desaparece" cada 2 segundos. Todo lo que queda hacer es que el sonido se genere de la forma más coordinada posible con respecto al movimiento de las olas para conseguir un resultado de lo más completo.\\

\begin{lstlisting}[style=C-color, caption={Generación de un sonido de olas},label=cod:seawavesound, escapechar=|]
float Sounds::CreateSeaWavesSound(float frequency, long int currentCount)
{
    return GetLowPassNoiseValue(0.1f) *
               GetSineWaveValue(frequency, currentCount) * 0.9 +
           GetLowPassNoiseValue(0.1f) * 0.1;
}
\end{lstlisting}

Una vez llegados a este punto, no obstante, tenía claro que aún no había llegado el momento de abandonar la geometría. Es una lástima, teniendo un efecto tan potente, no explotarlo un poco más. La primera idea que visualicé fue el mar digital que había creado descomponiéndose en cubos individuales. No obstante, si bien esta idea me fascinaba, también planteaba muchos inconvenientes, dada la complejidad que suponía convertir un solo objeto 3D en múltiples instancias separadas pero interconectadas y con su propio ciclo de vida y animación. Parecía una idea excesivamente ambiciosa y arriesgada, y teniendo en cuenta la posibilidad de que el resultado final acabase distando de aquel que tenía en mente, decidí optar por otras opciones.\\

La siguiente idea que se me ocurrió me fascinó del mismo modo que la anterior, y sin embargo, tras reflexionar sobre la misma, parecía bastante más factible: hacer que nuestro mar de puntos se transformase en una esfera perfecta.\\

Una de las formas en las que podemos generar una esfera en el espacio 3D es mediante el uso de \emph{anillos}. Esto consiste, básicamente, en generar una esfera a partir de circunferencias. En la imagen [\ref{fig:sphere}] podemos ver un ejemplo de una esfera formada por anillos interconectados.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=8cm]{archivos/sphere}
	\caption{Esfera formada por anillos}
	\label{fig:sphere}
\end{figure}

Tras un tiempo de desarrollo, conseguí establecer una conexión entre los puntos de la malla que habíamos generado y los puntos que forman una esfera. Podemos ver el resultado visual en la figura [\ref{fig:planeToSphere}]. Como podemos observar en la malla de este ejemplo, tenemos 7 grupos de color. Cada uno de estos grupos se correspondería con un anillo de la esfera. De este modo, los 4 vértices centrales, de color rojo, se corresponderían con el punto inferior de la esfera y los cuatro vértices de los extremos, en color naranja, convergerían en el punto superior de la esfera. Todos los vértices intermedios convergerían en distintos anillos, correspondiéndose, en el ejemplo, el color magenta con el anillo central de la esfera. Los colores azul claro y azul oscuro se corresponderían con el anillo inmediatamente superior e inferior al anillo central y así sucesivamente.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=8cm]{archivos/planeToSphere}
	\caption{Relación entre una malla de puntos y una esfera}
	\label{fig:planeToSphere}
\end{figure}

A continuación se adjunta el código que realiza esta asociación entre puntos de la malla y puntos de la esfera [\ref{cod:planeToSphere}]. Es bastante denso y requiere de una explicación detallada, teniendo en mente y como referencia las figuras [\ref{fig:sphere}] y [\ref{fig:planeToSphere}].\\

\begin{lstlisting}[style=C-color, caption={Método que establece una relación entre los vértices de un plano y una esfera},label=cod:planeToSphere, escapechar=[]
Point3D Imp_Geometry::GetPointInSphereFromPlane(const int posX, const int posY, const int gridSize, const float radius)
{
    const int halfGrid = gridSize / 2;

    const int firstQuarterPosX = (posX < gridSize / 2) ? posX : gridSize - posX - 1; [\label{line:quarterX}[
    const int firstQuarterPosY = (posY < gridSize / 2) ? posY : gridSize - posY - 1; [\label{line:quarterY}[

    const int ring = gridSize - 1 - firstQuarterPosX - firstQuarterPosY; //The numbers of rings goes from 1 to gridSize - 1 [\label{line:ring}[
    const float radiusSign = (ring < halfGrid) ? -1.f : 1.f;

    //top && bottom
    if (ring == 1 || ring == gridSize - 1)
    {
        return Point3D(0.f, radius * radiusSign, 0.f);
    }
    //middle ones
    else [\label{line:middlerings}[
    {
        const int positiveRing = (ring < halfGrid) ? ring : gridSize - ring;
        const float perRingHeight = radius / float(halfGrid - 1);[\label{line:perRingHeight}[
        float height = perRingHeight * (halfGrid - positiveRing) * radiusSign; [\label{line:height}[

        const float sine = height / radius;
        const float circleRadius = radius * sqrt(1 - sine * sine); //circleRadius = radius * cos()

        const float quarterCircle = Fast::PI / 2.f;

        float quadrant = CalculateQuadrant(posX, posY, halfGrid); [\label{line:quadrant}[

        const int positiveFirstQuarterPosX = (ring <= halfGrid) ? firstQuarterPosX - (halfGrid - ring) : firstQuarterPosX;
        const float angle = ((positiveFirstQuarterPosX + 1) / float(positiveRing)) * quarterCircle + quadrant;

        Point3D p = Point3D(circleRadius * cos(angle), height, circleRadius * sin(angle));
        return p;
    }
}
\end{lstlisting}

Empezamos estableciendo la siguiente relación: la cantidad de anillos de una esfera generada a partir de una malla es igual a la cantidad de vértices que forman la malla en una sola línea menos uno. En otras palabras, si tenemos una malla de 8x8, como la de la figura [\ref{fig:planeToSphere}], entonces la esfera resultante tendrá 7 anillos, dos de los cuales se corresponderán con el punto superiro e inferior de la esfera.\\

Además, para facilitar los cálculos, trasladamos cualquier punto de la malla al primer cuadrante de la misma, como vemos en las líneas [\ref{line:quarterX}] y [\ref{line:quarterY}]. De este modo, de cara a los cálculos, empezando en cero, los puntos (1, 6), (6, 6) y (6, 1) se asociarán al punto (1, 1) del primer cuadrante en la malla [\ref{fig:planeToSphere}]. De este modo, podemos tratar todos los puntos como si estuvieran en el mismo cuadrante, simplificando así nuestra tarea.\\

Una vez calculado esto, hallamos el número de anillo en el que nos hallamos, valor que va de 1 al tamaño de una línea de la malla menos 1, en nuestro ejemplo, de 1 a 7. Podemos ver este cálculo en la línea [\ref{line:ring}]. Como podemos ver, el anillo en que nos encontramos en la esfera se corresponde con el número de anillos menos la posición \emph{x} e \emph{y} que ocupamos en la malla (una vez trasladados al primer cuadrante). De este modo, ponemos de ejemplo el punto (7,6) que se corresponde con el punto (0,1) del primer cuadrante. Por tanto, hacemos el cálculo (\(anillos - 0 - 1\)) y obtenemos que nos hallamos en el anillo 6. Siendo el color rojo el primer anillo y el color naranja el último (7), vemos que efectivamente el color amarillo se corresponde con el anillo 6.\\

Una vez sabemos en qué anillo se encuentra nuestro punto, calculamos también su signo. Esto es, cualquier anillo por encima del anillo central tendrá un signo positivo y cualquier anillo por debajo, un signo negativo. Hacemos esto porque para formar nuestra esfera, la situamos en el origen de coordenadas, por lo que sabemos que el anillo central se situará en el plano \emph{y = 0}, y cualquier anillo que no sea el central tendrá una altura positiva o negativa, por lo que necesitaremos hallar su signo.\\

Con esto hecho, comprobamos si nuestro punto se encuentra en el primer o último anillo y de ser así, lo situamos en el origen y especificamos su altura, que será el radio positivo o negativo de la esfera, dependiendo del anillo.\\

Si nuestro anillo a calcular es uno de los centrales, el cáculo se vuelve, sin embargo, algo más complejo, como podemos ver a partir de la línea [\ref{line:middlerings}]. Empezamos por calcular el valor absoluto del anillo en el que nos encontramos. De este modo, el anillo 2 y 6 son equivalentes, y el 3 y el 5 también, ya que realmente se trata del mismo anillo pero con alturas opuestas. Además, calculamos la altura a la que se situará nuestro anillo en la esfera. Para ello, empezamos por calcular la distancia que hay entre dos anillos, como vemos en la línea [\ref{line:perRingHeight}], que se corresponde con el radio divido por la mitad del tamaño de la malla menos uno. De este modo, si tenemos una esfera con 8 vértices por línea y radio 90, la mitad de su tamaño menos 1 será 3 y por tanto el tamaño de cada incremento será de 30 unidades. Como vemos, esto concuerda con nuestro modelo, pues en nuestra esfera de siete anillos, con el anillo central situado en el origen, tenemos tres anillos por encima y tres anillos por debajo del central. Si vamos en incrementos de 30 en 30 unidades, entonces nuestro anillo superior e inferior se corresponderán con el radio definido, como debería ser.\\

A continuación, pasamos a calcular la altura a la que se encuentra nuestro anillo, como vemos en [\ref{line:height}]. Esta altura se corresponde con el valor positivo del anillo en el que nos encontramos restado a la mitad del anillo por el incremento por anillo por el signo. De este modo, si tenemos un punto que pertenece al anillo 6, este se corresponderá con el anillo 2. El anillo central en este ejemplo es el 4º, por lo que, \(4 - 2 = 2\), el signo será positivo, pues el anillo 6 se encuentra en la parte positiva de la esfera y el incremento será 30, por lo que el anillo 6 se situará a una altura de \(2 * 30 = 60\).\\

Una vez sabemos la altura a la que se sitúa nuestro anillo, llega el momento de emplear un poco de trigonometría para hallar el radio del anillo a la altura calculada. Usaremos como referencia la figura [\ref{fig:sphereTrigo}].\\

\begin{figure}[h]
	\centering
	\includegraphics[width=8cm]{archivos/sphereTrigo}
	\caption{Hallar \emph{r} a partir de \emph{R} y \emph{h}}
	\label{fig:sphereTrigo}
\end{figure}

Conocemos el valor del cateto que se corresponde con la altura \emph{h}, a la que se sitúa nuestro anillo, y la hipotenusa que se corresponde con el radio \emph{R} de nuestra esfera, y debemos hallar el radio \emph{r} de nuestro anillo. Para ello, calculamos \(\frac{R}{h}\) para hallar el valor del seno del cateto opuesto. Sin embargo, para poder calcular \emph{r} necesitamos el valor del coseno. Por suerte, hay una fórmula matemática que nos resuelve este problema, pues el valor del coseno de un ángulo es equivalente a la raíz cuadrada de 1 menos el valor cuadrado del seno del ángulo, es decir \(\cos(\alpha) = \sqrt{1 - \sin(\alpha)^2}\). De este modo, hemos hallado el valor del coseno entre \emph{r} y \emph{R}, por lo que basta con multiplicar \emph{R} por el valor obtenido para hallar el radio \emph{r} de nuestro anillo.\\

Tras ello, en la línea [\ref{line:quadrant}], invocamos una función que nos devuelve, dependiendo del cuadrante en el que nos situemos, un ángulo distinto. Así pues, el primer cuadrante empezará en 0, el segundo en \(\frac{\pi}{2}\), el tercero en \(\pi\) y el cuarto en \(\frac{3\pi}{2}\). Así, una vez teniendo este ángulo como base, calculamos la posición en el anillo en que se encuentra nuestro punto, que se corresponderá a la posición relativa del punto en el anillo para el primer cuadrante más el valor del ángulo para el cuadrante en el que nos encontramos. Para hallar la posición relativa de nuestro punto en la circunferencia, lo que hacemos es tomar el valor de la \emph{x} en el primer cuadrante. Si nos fijamos, el primer anillo de la circunferencia tendrá 1 vértice por cuadrante, el segundo, 2, el tercero, 3 y así sucesivamente. Así pues, sabiendo el anillo en el que nos encontramos y el desplazamiento en \emph{x}, podemos hallar el ángulo que corresponde al punto. Por ejemplo, un punto situado en (1, 1) está en el 5 anillo, que se corresponde con el tercero. Por tanto, sabemos que el punto (1, 1) tendrá tres vértices en el primer cuadrante. Como estamos en el vértice 1, empezando por 0, de los tres vértices que tiene el tercer anillo por cuadrante, estamos pues a \(\frac{2}{3}\) de progreso en el cuadrante, por lo que multiplicamos este valor por el valor de un cuadrante (\(\frac{\pi}{2}\)) y le sumamos el desplazamiento calculado en función del cuadrante en que nos hallamos para saber con qué ángulo de la circunferencia se corresponde nuestro vértice.\\

Tras todo este largo proceso, calculamos y almacenamos el valor del punto y creamos una función que nos permita interpolar entra la posición de los puntos en el plano y la posición de los vértices equivalentes en la esfera. En la imagen [\ref{fig:finalSphere}] podemos ver el resultado final. El resultado que se incluye en la demo es un poco distinto al que se muestra en esta figura, ya que se ha iterado y refinado para darle un toque más interesante.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=8cm]{archivos/finalSphere}
	\caption{Esfera a partir del plano}
	\label{fig:finalSphere}
\end{figure}

Tras ello, pasamos a jugar un poco con el resultado obtenido, refinándolo, animando el tamaño y fase de la esfera y añadiendo música que suene acorde. Llegamos incluso a dejar de dibujar la esfera línea a línea para dibujarla como un mar de puntos, lo cual genera un efecto visualmente atractivo.\\

Una vez tenemos esto hecho, podemos decir que hemos dedicado suficiente tiempo al efecto de geometría, y llega el momento de pasar a implementar otros efectos. En cuestión, de los efectos que nos quedan por implementar, hay varios que son similares entre ellos, pues todo lo que hacen es operar sobre una textura. Estos son el efecto de plasma [\ref{sec:plasma}], el efecto de RotoZoom [\ref{sec:rotozoom}] y el efecto de deformaciones [\ref{sec:deformaciones}]. ¿Y si los combinamos todos en uno? Podríamos crear una textura de plasma animada a la que aplicamos una deformación y rotamos y escalamos al estilo del más clásico RotoZoom.\\

Aplicar este efecto es muy sencillo, y sin embargo, el resultado visual es de lo más satisfactorio. Empezamos por escribir en una textura la frase "\emph{did you ask for plasma?}", en español, "¿has pedido plasma?". Dibujamos esta textura inicialmente en blanco, sobre fondo negro, y la hacemos aparecer con un \emph{zoom in} consistente en un escalado básico.\\

A continuación, pintamos nuestro plasma sobre la textura, pero de forma selectiva: coloreamos con el valor correspondiente sólo aquellos píxeles que son blancos, de forma que el texto se colorea con el efecto de plasma pero el fondo sigue siendo negro.\\

Una vez hecho esto, aplicamos el efecto de deformación de bandera que ya vimos en el apartado de deformaciones [\ref{sec:deformaciones}], de modo que nuestro texto empieza a ondear. A nivel personal, el resultado me parece de lo más satisfactorio, ya que ver el plasma animado, de naturaleza ya por sí ondulante sobre un texto animado ondulado produce un efecto visual de lo más atractivo. Para acabar de coronar esta transformación, aplicamos el efecto de RotoZoom, de modo que toda la escena que hemos construido, con el plasma animado sobre el texto ondulado, culmina con su desaparición rotando cada vez más rápido y haciéndose cada vez más pequeño, hasta que se produce un fundido de salida a blanco.\\ 

Podemos ver distintas capturas de lo descrito en la figura [\ref{fig:finalPlasma}]. No obstante, si nos damos cuenta, se aplica una gran cantidad de operaciones por píxel en esta parte de la demo. Si bien es cierto que manejamos una resolución HD (1280x720), aun así tantas transformaciones pueden resultar excesivas, y afectar de forma considerable a la tasa de fotogramas de la demo. Es por ello que, nuevamente, tenemos que tomar una decisión crítica: sacrificar resolución por rendimiento. No vamos a bajar de calidad HD, sin embargo, es sólo que la textura que vamos a usar y sobre la que aplicaremos todos los cáculos y transformaciones tendrá una resolución menor, concretamente, de la mitad de la altura y anchura de la pantalla, quedándonos en \(640 \times 360 = 230400\) píxeles, cuatro veces menos que la cantidad que manejamos en pantalla. De este modo, iteraremos sobre una textura relativamente pequeña que a continuación escalaremos a la resolución de nuestra demo y que a su vez el sistema escalará a la resolución de la pantalla.\\

Esta vez, sin embargo, la pérdida de resolución resulta mucho más notoria. Por suerte, no obstante, debido a que esta parte de la demo es especialmente dinámica, la bajada en resolución resulta menos aparente, con lo cual conseguimos mantener una tasa de fotogramas adecuada sin impactar excesivamente el resultado de nuestra demo.\\

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/plasma5}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/plasma6}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/plasma7}
	\end{subfigure}
	\caption{Distintas capturas del efecto de plasma + deformaciones + RotoZoom}
	\label{fig:finalPlasma}
\end{figure}

A lo largo de la parte final del efecto de geometría y durante la primera parte del efecto de plasma, utilizamos varios sonidos que no hemos visto hasta ahora. Se trata del sonido de láser y de los sonidos de percusión.\\

\begin{lstlisting}[style=C-color, caption={Otros sonidos empleados en la demo},label=cod:moresound, escapechar=[]
float Sounds::CreateLaserSound(float frequency, long int currentCount)
{
    return (GetSawtoothWaveValue(frequency, currentCount) * 0.5f +
            GetSawtoothWaveValue(frequency, currentCount) * 0.5f * GetHighPassNoiseValue(0.05)) *
               0.5 +
           GetHighPassNoiseValue(0.05) * 0.5;
}


Envelope laserEnv = {0.0f, 0.f, 0.0f, 0.2f, 1.f, 1.0f};

Envelope drumEnv = {0.f, 0.f, 0.f, 0.1f, 1.f, 1.f};
Envelope snareEnv = {0.f, 0.f, 0.f, 0.3f, 0.5f, 0.5f};
\end{lstlisting}

Como podemos ver en el código [\ref{cod:moresound}], añadimos un nuevo sonido al que hemos bautizado como sonido de láser. Es un efecto muy sencillo en el que generamos el sonido a partir de una onda de diente de sierra más una segunda onda modulada en función de un filtro pasa alta. Esto crea un efecto de distorsión en el sonido, que sumado al sonido metálico de la onda de diente de sierra, resulta en una sensación con un cierto aire de película de ciencia ficción. Envolvemos este sonido en una envolvente muy breve que entra en fase de relajación desde el inicio.\\

Para los instrumentos percutivos, todo lo que hacemos es aplicar una envolvente distinta a un ruido blanco. Siendo la primera envolvente similar a la de un tambor (\emph{drumEnv}), y siendo la segunda, con un mayor tiempo de relajación y un volumen de base menor, más similar al ruido de una caja (\emph{snareEnv}).\\

El sonido que suena, sin embargo, mientras que nuestra textura de plasma empieza a rotar y disminuir en tamaño hasta hacerse irreconocible es bastante más interesante. Quería generar una sensación de sonido que resultase agobiante y causase la ilusión de un sonido constantemente ascendente. Para ello, intenté generar la ilusión o escala de Shepard. Podemos ver la implementación en el código [\ref{cod:shepard}].

\begin{lstlisting}[style=C-color, caption={Generación de la escala de Shepard},label=cod:shepard]
const float mask[12] = {0.01f, 0.025f, 0.05f, 0.075f, 0.14f, 0.2f, 0.2f, 0.14f, 0.075f, 0.05f, 0.025f, 0.01f};

static float baseFrequency = 261.63 * 0.125;
const static float incrementer = 1.059463f;

//Generate Sephard illusion of ascending sound
notes.push_back({Sounds::GetSineWaveValue, laserEnv, baseFrequency * 1, mask[1] * volume, 0.3f});
notes.push_back({Sounds::GetSineWaveValue, laserEnv, baseFrequency * 2, mask[3] * volume, 0.7f});
notes.push_back({Sounds::GetSineWaveValue, laserEnv, baseFrequency * 4, mask[5] * volume, 0.3f});
notes.push_back({Sounds::GetSineWaveValue, laserEnv, baseFrequency * 6, mask[7] * volume, 0.7f});
notes.push_back({Sounds::GetSineWaveValue, laserEnv, baseFrequency * 8, mask[9] * volume, 0.3f});
notes.push_back({Sounds::GetSineWaveValue, laserEnv, baseFrequency * 10, mask[11] * volume, 0.7f});

baseFrequency *= incrementer;
if (baseFrequency >= 523.f)
{
	baseFrequency = 261.63f;
}
\end{lstlisting}

La ilusión de Shepard es una ilusión auditiva que produce la sensación de ascenso infinito cuando en realidad reproducimos un sonido en bucle. Este efecto se consigue, dada una frecuencia, generando varios armónicos de la misma (6 en nuestro código) y aplicando un volumen distinto a cada uno (como vemos, el volumen de cada armónico queda determinado por un conjunto de valor constante que definimos). De este modo, cada vez que reproducimos una nueva nota, aumentamos su frecuencia en un semitono (\(2^{\frac{1}{12}} = 1.059463\)), hasta que llegamos a la octava (el doble de la frecuencia) y en ese momento volvemos a la frecuencia base.\\

¿Por qué se produce esta sensación de circularidad, sin embargo? Es realmente difícil de explicar con palabras o imágenes, por lo que recomiendo el siguiente \emph{\textbf{\href{https://www.youtube.com/watch?v=ev9hrqkhWsM}{vídeo}}}. No obstante, trataré de explicarlo: esto se debe a que, como aplicamos una máscara que atenúa el volumen de los armónicos más graves y más agudos, aquellos que destacan son los armónicos centrales. A su vez, la frecuencia de estos armónicos aumenta por iteración. Como cada vez que completamos una octava, empezamos el bucle de nuevo, el sonido de la frecuencia fundamental, que inicialmente era 261.63, en la interación anterior a reiniciar el bucle tiene un valor de 493.89, de modo que cuando reiniciamos el bucle, el valor de la frecuencia fundamental vuelve a ser 261.63 pero el valor del siguiente armónico (\emph{baseFrequency * 2}) pasa a ser 523.26, siendo este el equivalente de aumentar 493.89 en un semitono. Por tanto, se produce una sensación de circularidad, ya que cuando se repite el bucle, el último valor de la iteración mantiene continuidad con respecto al primer valor de la próxima iteración del siguiente armónico. Además, el hecho de atenuar las frecuencias más bajas y altas contribuye aún más a reforzar esta sensación de continuidad y disimular la repetición del bucle (pues las frecuencias que rompen su continuidad al repetirse el bucle, que están a los extremos, suenan con mucha menor intensidad).\\

Gracias a este efecto, logramos causar la sensación que buscábamos. Además, para reforzar esta misma impresión aun más, recortamos la distancia temporal que pasa entre una nota y la siguiente, de modo que los sonidos se reproducen cada vez más juntos, reforzando la sensación de agobio y crecimiento.\\

Este sonido culmina con un fundido de salida al silencio que se coordina con el fundido de salida visual del efecto, quedando por unos instantes una pantalla vacía, en blanco, y sin sonido. Llega el momento de pasar al próximo efecto.\\

En esta nueva escena pondremos en práctica el efecto de planos infinitos de un modo que no habíamos empleado hasta ahora. Generaremos una textura de gran tamaño sobre la que escribiremos mensajes de texto, e iremos recorriendo la escena como si la estuviésemos viendo en primera persona, de modo que dé tiempo a leer cada uno de los mensajes.\\

En el mundo de la \emph{demoscene}, los mensajes de texto, retos o incluso mofas entre \emph{demosceners}, a veces ocultos y a veces en primer plano, son algo de lo más común a encontrar dentro de una demo. Es por tanto una oportunidad que no vamos a dejar pasar. Esto es lo que escribiremos en nuestra textura "\emph{A CPU is so slow... A CPU is not for graphics... Wait... Am I dreaming? Is this heaven? Can't be true...}", es español, "\emph{Una CPU es tan lenta... Una CPU no es para gráficos... Espera... ¿Estoy soñando? ¿Es esto el cielo? No puede ser cierto...}". Dejamos así nuestra pequeña reivindicación personal.\\

Reforzamos este efecto reflejando la mitad inferior de la pantalla en la mitad superior, de modo que todo sea vea espejado, y añadimos una línea negra en el centro a modo de horizonte, tanto por cuestión estética como para facilitar la orientación en la escena.\\

Una vez hecho esto, definimos un mapa de posiciones e interpolamos entre ellas, de modo que podamos recorrer de forma automática nuestra escena. El resultado se puede apreciar en la figura [\ref{fig:heaven}].\\

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/planes4}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/planes5}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/planes6}
	\end{subfigure}
	\caption{Distintas capturas del efecto de planos infinitos}
	\label{fig:heaven}
\end{figure}

Para reforzar la sensación etérea que causa este efecto, buscamos generar un sonido que suene etéreo. Para ello, buscamos sonidos y referencias que nos gusten y las analizamos, tanto desde el punto de vista del tipo de envolvente que tienen como analizamos también su espectro de frecuencias, para ver en cuántas frecuencias suenan y de qué forma lo hacen. El resultado tras el análisis es el siguiente código [\ref{cod:synth}].\\

\begin{lstlisting}[style=C-color, caption={Generación de un sonido etéreo},label=cod:synth]
float Sounds::CreateSynthSound(float frequency, long int currentCount)
{
    const float LFO = GetSineWaveValue(2, currentCount);
    return GetTriangleWaveValue(frequency * 1.0, currentCount) * (0.45 + 0.1 * LFO) * 0.6 +
           GetTriangleWaveValue(frequency * 1.3333, currentCount) * (0.45 + 0.1 * LFO) * 0.1 +
           GetTriangleWaveValue(frequency * 1.6666, currentCount) * (0.45 + 0.1 * LFO) * 0.1 +
           GetTriangleWaveValue(frequency * 2.0, currentCount) * (0.45 + 0.1 * LFO * 2.f) * 0.1 +
           GetTriangleWaveValue(frequency * 2.6666, currentCount) * (0.45 + 0.1 * LFO * -1.f) * 0.1 +
           GetTriangleWaveValue(frequency * 4.0, currentCount) * (0.45 + 0.1 * LFO) * 0.1 +
           GetTriangleWaveValue(frequency * 5.3333, currentCount) * (0.45 + 0.1 * LFO * 2.f) * 0.1 +
           GetTriangleWaveValue(frequency * 6.6666, currentCount) * (0.45 + 0.1 * LFO * -1.f) * 0.1;
}

Envelope synthEnv = {1.f, 1.f, 1.f, 2.f, 1.f, 0.7f};
\end{lstlisting}

Para que nuestro sonido suene etéreo, entre otras cosas necesitamos que tanto su fase de ataque como de relajación sean lentas, de modo que entre y se desvanezca de forma suave y poco agresiva. Del mismo modo, un sonido etéreo debe sonar armónico y organizado pero debe causar una cierta sensación de fragilidad o inestabilidad. Esta sensación la logramos con el uso de un oscilador en baja frecuencia (\emph{low frequency oscillator}, LFO\footnote{\url{https://en.wikipedia.org/wiki/Low-frequency_oscillation}}) que aplicamos de forma individual sobre el volumen de cada uno de los armónicos que conforman nuestra frecuencia, aplicando además distintos valores de intensidad. De este modo se produce una sensación de irregularidad o inestabilidad dentro de un sonido que suena de forma armónica, pero al mismo tiempo, titilante, logrando ese difícil equilibro entre armonía y fragilidad.\\

Con esto hecho, pasamos a implementar la que será la última parte de nuestra demo, el túnel de puntos [\ref{sec:dottunnel}]. Tras una pequeña transición en la que rotamos la línea que pintábamos sobre el horizonte de modo que se sitúe en vertical, aplicando la misma transformación que ya hemos visto tantas veces [\ref{fig:transform}], pasamos a mostrar nuestro túnel de puntos.\\

Para ello, empezamos con una transición inicial en la que vamos pintando la pantalla de negro desde el centro hacia ambos extremos de la misma. Al mismo tiempo, empezamos a dibujar el túnel, aunque sólo pintaremos aquellos puntos del mismo que se hallen dentro de la zona negra. Tras ello, nos limitamos a seguir actualizando nuestro túnel durante unos instantes, mientras incorporamos música muy sencilla a la escena. Simplemente reproducimos notas con el sonido del láser mientras que suenan instrumentos percutivos. Sincronizamos, no obstante, la percusión con el túnel, de modo que cada vez que suena un golpe, el túnel acelera brevemente.\\

Tras ello, con un fundido de entrada pasamos a mostrar los créditos de la demo, dibujándolos encima del túnel. Para dar un pequeño efecto de dinamismo, no obstante, se modifica levemente la posición del texto en función de la trayectoria del túnel, creando así la sensación de que el texto se mueve al compás que el túnel avanza. Podemos ver los efectos descritos anteriormente en la figura[\ref{fig:finaltunel}].\\

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/tunel1}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/tunel2}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=4.5cm]{archivos/tunel3}
	\end{subfigure}
	\caption{Distintas capturas del efecto de túnel de puntos}
	\label{fig:finaltunel}
\end{figure}

Ya por último, con un fundido a negro y un desvanecimiento progresivo de la música, la demo finaliza.

\section{Conclusiones de la demo}

Y hasta aquí llega el desarrollo de la demo final. Lo cierto es que ha sido un desarrollo de lo más interesante. Durante la realización de los efectos gráficos por separado no era consciente de hasta qué punto se podían estirar o combinar estos efectos para producir resultados que anteriormente hubieran parecido imposibles.\\

Lo cierto es que con el set de técnicas aprendido, de pronto aparece una gran cantidad de posibilidades y una infinidad de combinaciones.\\

Es así como esta demo supone la culminación de todo lo aprendido anteriormente, y si cada uno de los efectos gráficos estudiados era un pequeño ladrillo, ahora se nos abre la posibilidad de construir una gran estructura, donde la creatividad y el ingenio son primordiales, ya que las barreras de aquello que podemos lograr se encuentran más en los límites de nuestra imaginación que en los límites del ordenador.\\

Esta demo está ejecutada únicamente en CPU, en un sólo hilo (aunque la librería de sonido genera un hilo separado para la reproducción de audio) y cuenta con una combinación de efectos gráficos en dos dimensiones y algunos que simulan la tridimensionalidad. Todo esto ejecutado en tiempo real.\\

Además, en la demo hemos abierto la posibilidad de generar sonido, lo cual ha creado un inmenso campo de posibilidades que sin embargo ha habido que limitar para no salir del ámbito de este trabajo. Aun así, hemos conseguido generar una gran cantidad de sonidos en tiempo real, coordinados con la acción en pantalla y que intentan reforzar aquello que sucede en la misma. Además, la demo se reproduce en estéreo, y algunos sonidos tienen un posicionamiento definido, por lo que se recomienda escucharla con auriculares.\\

Por tanto, esta demo representa no solo una aplicación de todo lo aprendido, si no también la apertura ante un amplio abanico de posibilidades, tanto desde el punto de visto técnico como creativo, y que me gustaría poder seguir ampliando y refinando a lo largo del tiempo, una vez finalizado este trabajo.\\